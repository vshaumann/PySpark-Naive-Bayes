{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.feature import IDF\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos = sc.textFile('NB_files/train_pos.txt')\n",
    "train_neg = sc.textFile('NB_files/train_neg.txt')\n",
    "test_pos = sc.textFile('NB_files/test_pos.txt')\n",
    "test_neg = sc.textFile('NB_files/test_neg.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['a', 'able', 'about', 'across', 'after', 'all', 'almost', 'also',\n",
    "              'am', 'among', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because',\n",
    "              'been', 'but', 'by', 'can', 'cannot', 'could', 'dear',\n",
    "              'did', 'do', 'does', 'either', 'else', 'ever', 'every', 'for',\n",
    "              'from', 'get', 'got', 'had', 'has', 'have', 'he', 'her', 'hers',\n",
    "              'him', 'his', 'how', 'however', 'i', 'if', 'in', 'into', 'is',\n",
    "              'it', 'its', 'just', 'least', 'let', 'like', 'likely', 'may',\n",
    "              'me', 'might', 'most', 'must', 'my', 'neither', 'no', 'nor',\n",
    "              'not', 'of', 'off', 'often', 'on', 'only', 'or', 'other', 'our',\n",
    "              'own', 'rather', 'said', 'say', 'says', 'she', 'should', 'since',\n",
    "              'so', 'some', 'than', 'that', 'the', 'their', 'them', 'then',\n",
    "              'there', 'these', 'they', 'this', 'tis', 'to', 'too', 'twas', 'us',\n",
    "              've', 'wants', 'was', 'we', 'were', 'what', 'when', 'where', 'which',\n",
    "              'while', 'who', 'whom', 'why', 'will', 'with', 'would', 'yet',\n",
    "              'you', 'your']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(blob):\n",
    "    blob = blob.split('\\n')\n",
    "    blob = [re.sub('[^A-Za-z]', ' ', i) for i in blob]\n",
    "    blob = [i.split() for i in blob]\n",
    "    blob = [item for sublist in blob for item in sublist]\n",
    "    blob = [word.strip().lower() for word in blob if word not in stop_words if len(word) >= 3]\n",
    "    return blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse Text into Words\n",
    "train_pos_bag = train_pos.map(parse)\n",
    "train_neg_bag = train_neg.map(parse)\n",
    "test_pos_bag = test_pos.map(parse)\n",
    "test_neg_bag = test_neg.map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TF Mapping\n",
    "train_tf_pos = HashingTF().transform(train_pos_bag)\n",
    "train_tf_neg = HashingTF().transform(train_neg_bag)\n",
    "test_tf_pos = HashingTF().transform(test_pos_bag)\n",
    "test_tf_neg = HashingTF().transform(test_neg_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IDF Transformation\n",
    "train_idf_pos = IDF().fit(train_tf_pos)\n",
    "train_idf_neg = IDF().fit(train_tf_neg)\n",
    "test_idf_pos = IDF().fit(test_tf_pos)\n",
    "test_idf_neg = IDF().fit(test_tf_neg)\n",
    "\n",
    "train_tfidf_pos = train_idf_pos.transform(train_tf_pos)\n",
    "train_tfidf_neg = train_idf_neg.transform(train_tf_neg)\n",
    "test_tfidf_pos = test_idf_pos.transform(test_tf_pos)\n",
    "test_tfidf_neg = test_idf_neg.transform(test_tf_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label Positive and Negative\n",
    "train_tfidf_pos = train_tfidf_pos.map(lambda x: LabeledPoint(1, x))\n",
    "train_tfidf_neg = train_tfidf_neg.map(lambda x: LabeledPoint(0, x))\n",
    "test_tfidf_pos = test_tfidf_pos.map(lambda x: LabeledPoint(1, x))\n",
    "test_tfidf_neg = test_tfidf_neg.map(lambda x: LabeledPoint(0, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnionRDD[41] at union at NativeMethodAccessorImpl.java:-2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join Positive and Negative\n",
    "train_all_tfidf = train_tfidf_pos.union(train_tfidf_neg)\n",
    "test_all_tfidf = test_tfidf_pos.union(test_tfidf_neg)\n",
    "\n",
    "train_all_tfidf.cache()\n",
    "test_all_tfidf.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY:   0.782765531062\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_all_tfidf.randomSplit([0.6, 0.4], seed = 0)\n",
    "\n",
    "model_train = NaiveBayes.train(train_data)\n",
    "predictionAndLabel = test_data.map(lambda p : (model_train.predict(p.features), p.label))\n",
    "train_accuracy = 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / test_data.count()\n",
    "print \"TRAINING ACCURACY:  \", train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY:   0.782765531062\n"
     ]
    }
   ],
   "source": [
    "#### TRAIN SET ACCURACY ####\n",
    "\n",
    "train_data, test_data = train_all_tfidf.randomSplit([0.6, 0.4], seed = 0)\n",
    "\n",
    "model_train = NaiveBayes.train(train_data)\n",
    "predictionAndLabel = test_data.map(lambda p : (model_train.predict(p.features), p.label))\n",
    "train_accuracy = 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / test_data.count()\n",
    "print \"TRAINING ACCURACY:  \", train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY:   0.72904\n"
     ]
    }
   ],
   "source": [
    "#### TEST SET ACCURACY ####\n",
    "\n",
    "model_test = NaiveBayes.train(train_all_tfidf)\n",
    "predictionAndLabel = test_all_tfidf.map(lambda p : (model_test.predict(p.features), p.label))\n",
    "test_accuracy = 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / test_all_tfidf.count()\n",
    "print \"TEST ACCURACY:  \", test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
